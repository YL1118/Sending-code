# -*- coding: utf-8 -*-
"""
sync_general_subject.py
å¾ test_json_more_forall è£œé½Š parsed çš„ general_subjectï¼ˆåŒåæª”ã€åŒé¡åˆ¥ï¼‰ã€‚
è‹¥ parsed çš„ general_subject ç‚ºç©ºï¼Œä¸”ä¾†æºæœ‰å€¼ï¼Œå‰‡å¯«å› parsedã€‚

çµæ§‹ï¼š
  parsed/<category>/*.json
  test_json_more_forall/<category>/*.json

ä½¿ç”¨:
æœ€å®‰å…¨è©¦è·‘ï¼ˆä¸å¯«æª”ï¼‰ï¼š
python sync_general_subject.py --dry-run

æ­£å¼åŸ·è¡Œä¸¦å‚™ä»½ï¼š
python sync_general_subject.py --backup

åªè·‘ç‰¹å®šé¡åˆ¥ï¼ˆä¾‹å¦‚ é€šçŸ¥å‡½ èˆ‡ ä¿å–®æŸ¥è©¢ï¼‰ï¼š
python sync_general_subject.py --categories é€šçŸ¥å‡½ ä¿å–®æŸ¥è©¢

æ¬„ä½ä¸æ˜¯ general_subject æ™‚ï¼ˆå¯æ”¹ï¼‰ï¼š
python sync_general_subject.py --key subject_summary

"""

import argparse
import json
import shutil
from pathlib import Path
from typing import Any, Tuple

def is_empty_value(v: Any) -> bool:
    """å®šç¾© 'ç©º'ï¼šNoneã€ç¼ºéµã€ç©ºå­—ä¸²æˆ–åªå«ç©ºç™½ã€‚éå­—ä¸²é¡å‹å‰‡ä»¥ bool(v) åˆ¤æ–·ã€‚"""
    if v is None:
        return True
    if isinstance(v, str):
        return len(v.strip()) == 0
    return not bool(v)

def load_json(p: Path) -> Tuple[dict, bool]:
    try:
        with open(p, "r", encoding="utf-8") as f:
            return json.load(f), True
    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•—ï¼š{p} -> {e}")
        return {}, False

def save_json(p: Path, obj: dict) -> bool:
    try:
        with open(p, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ å¯«å…¥å¤±æ•—ï¼š{p} -> {e}")
        return False

def main():
    ap = argparse.ArgumentParser(description="æ¯”å°å…©å€‹è³‡æ–™å¤¾ï¼Œè‹¥ parsed æª”æ¡ˆçš„ general_subject ç‚ºç©ºå‰‡ç”¨ä¾†æºè£œé½Š")
    ap.add_argument("--parsed-root", type=str, default="parsed", help="è¦è¢«è£œé½Šçš„æ ¹ç›®éŒ„")
    ap.add_argument("--source-root", type=str, default="test_json_more_forall", help="ä¾†æºæ ¹ç›®éŒ„ï¼ˆæä¾› general_subjectï¼‰")
    ap.add_argument("--key", type=str, default="general_subject", help="è¦åŒæ­¥çš„æ¬„ä½éµå")
    ap.add_argument("--dry-run", action="store_true", help="è©¦è·‘ï¼šä¸å¯«æª”ï¼Œåªåˆ—å°å‹•ä½œ")
    ap.add_argument("--backup", action="store_true", help="å¯«æª”å‰å»ºç«‹å‚™ä»½ï¼ˆé¡å°„è·¯å¾‘ï¼‰")
    ap.add_argument("--backup-root", type=str, default="_backup_sync", help="å‚™ä»½æ ¹ç›®éŒ„ï¼ˆåœ¨ parsed-root å…§å»ºç«‹ï¼‰")
    ap.add_argument("--categories", nargs="*", default=None, help="åªè™•ç†æŒ‡å®šé¡åˆ¥è³‡æ–™å¤¾ï¼ˆç©ºå‰‡å…¨éƒ¨ï¼‰")
    args = ap.parse_args()

    parsed_root = Path(args.parsed_root)
    source_root = Path(args.source_root)
    if not parsed_root.exists():
        raise SystemExit(f"æ‰¾ä¸åˆ° parsed-rootï¼š{parsed_root.resolve()}")
    if not source_root.exists():
        raise SystemExit(f"æ‰¾ä¸åˆ° source-rootï¼š{source_root.resolve()}")

    cats = [d for d in parsed_root.iterdir() if d.is_dir()]
    if args.categories:
        allow = set(args.categories)
        cats = [d for d in cats if d.name in allow]

    if not cats:
        print("âš ï¸ æ²’æœ‰å¯è™•ç†çš„é¡åˆ¥è³‡æ–™å¤¾ã€‚")
        return

    backup_root = parsed_root / args.backup_root
    if args.backup and not args.dry_run:
        backup_root.mkdir(parents=True, exist_ok=True)

    total_checked = 0
    total_updated = 0
    total_skipped_no_source = 0
    total_skipped_not_empty = 0
    total_skipped_source_empty = 0
    total_errors = 0

    print(f"ğŸš€ é–‹å§‹ï¼šparsed={parsed_root.resolve()}  source={source_root.resolve()}")
    print(f"éµï¼š{args.key}ï¼›dry-run={'æ˜¯' if args.dry_run else 'å¦'}ï¼›backup={'æ˜¯' if args.backup else 'å¦'}")

    for cat_dir in sorted(cats, key=lambda p: p.name):
        cat = cat_dir.name
        src_cat_dir = source_root / cat
        if not src_cat_dir.exists():
            print(f"â„¹ï¸ é¡åˆ¥ã€Œ{cat}ã€åœ¨ä¾†æºä¸å­˜åœ¨ï¼Œç•¥éæ•´å€‹é¡åˆ¥ã€‚")
            continue

        for p_json in sorted(cat_dir.glob("*.json")):
            total_checked += 1
            q_json = src_cat_dir / p_json.name
            if not q_json.exists():
                total_skipped_no_source += 1
                print(f"   â†ªï¸ ç„¡å°æ‡‰ä¾†æºï¼š{cat}/{p_json.name}ï¼ˆç•¥éï¼‰")
                continue

            parsed_obj, ok1 = load_json(p_json)
            source_obj, ok2 = load_json(q_json)
            if not (ok1 and ok2):
                total_errors += 1
                continue

            parsed_val = parsed_obj.get(args.key, None)
            source_val = source_obj.get(args.key, None)

            if not is_empty_value(parsed_val):
                total_skipped_not_empty += 1
                # æœ‰å€¼å°±ä¸å‹•
                continue

            if is_empty_value(source_val):
                total_skipped_source_empty += 1
                # ä¾†æºä¹Ÿæ²’å€¼
                continue

            # è¦æ›´æ–°
            print(f"âœ” è£œé½Šï¼š{cat}/{p_json.name}  <-  ä¾†æº {args.key}ï¼ˆé•·åº¦={len(source_val) if isinstance(source_val, str) else 'n/a'}ï¼‰")
            parsed_obj[args.key] = source_val

            if args.dry_run:
                continue

            # å‚™ä»½
            if args.backup:
                backup_path = backup_root / cat / p_json.name
                backup_path.parent.mkdir(parents=True, exist_ok=True)
                try:
                    shutil.copy2(str(p_json), str(backup_path))
                except Exception as e:
                    print(f"   âš ï¸ å‚™ä»½å¤±æ•—ï¼š{p_json} -> {e}")

            if save_json(p_json, parsed_obj):
                total_updated += 1
            else:
                total_errors += 1

    print("â€”â€” çµ±è¨ˆ â€”â€”")
    print(f"æª¢æŸ¥æª”æ¡ˆï¼š{total_checked}")
    print(f"å·²æ›´æ–°ï¼š{total_updated}")
    print(f"ç•¥éï¼ˆä¾†æºä¸å­˜åœ¨ï¼‰ï¼š{total_skipped_no_source}")
    print(f"ç•¥éï¼ˆparsed åŸæœ¬ä¸ç©ºï¼‰ï¼š{total_skipped_not_empty}")
    print(f"ç•¥éï¼ˆä¾†æºä¹Ÿç‚ºç©ºï¼‰ï¼š{total_skipped_source_empty}")
    print(f"éŒ¯èª¤ï¼š{total_errors}")
    if args.backup and not args.dry_run and total_updated > 0:
        print(f"å‚™ä»½ä½ç½®ï¼š{(parsed_root / args.backup_root).resolve()}")

if __name__ == "__main__":
    main()
